{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c92889d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/simmin-u/opt/anaconda3/lib/python3.9/site-packages (1.10.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/simmin-u/opt/anaconda3/lib/python3.9/site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: opencv-python in /Users/simmin-u/opt/anaconda3/lib/python3.9/site-packages (4.5.5.62)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/simmin-u/opt/anaconda3/lib/python3.9/site-packages (from opencv-python) (1.20.3)\n",
      "Requirement already satisfied: torchvision in /Users/simmin-u/opt/anaconda3/lib/python3.9/site-packages (0.11.2)\n",
      "Requirement already satisfied: torch==1.10.1 in /Users/simmin-u/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (1.10.1)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /Users/simmin-u/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: numpy in /Users/simmin-u/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (1.20.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/simmin-u/opt/anaconda3/lib/python3.9/site-packages (from torch==1.10.1->torchvision) (3.10.0.2)\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 8.1 MB/s eta 0:00:01     |███████████████▊                | 2.8 MB 8.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /Users/simmin-u/opt/anaconda3/lib/python3.9/site-packages (from tensorboard) (1.20.3)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.43.0-cp39-cp39-macosx_10_10_x86_64.whl (4.2 MB)\n",
      "Collecting protobuf>=3.6.0\n",
      "  Downloading protobuf-3.19.3-cp39-cp39-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 34.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /Users/simmin-u/opt/anaconda3/lib/python3.9/site-packages (from tensorboard) (58.0.4)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.4.1-py2.py3-none-any.whl (157 kB)\n",
      "\u001b[K     |████████████████████████████████| 157 kB 41.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /Users/simmin-u/opt/anaconda3/lib/python3.9/site-packages (from tensorboard) (2.26.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/simmin-u/opt/anaconda3/lib/python3.9/site-packages (from tensorboard) (0.37.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 46.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /Users/simmin-u/opt/anaconda3/lib/python3.9/site-packages (from tensorboard) (2.0.2)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: six in /Users/simmin-u/opt/anaconda3/lib/python3.9/site-packages (from absl-py>=0.4->tensorboard) (1.16.0)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/simmin-u/opt/anaconda3/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/simmin-u/opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/simmin-u/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/simmin-u/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/simmin-u/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/simmin-u/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (2021.10.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\n",
      "Successfully installed absl-py-1.0.0 cachetools-5.0.0 google-auth-2.4.1 google-auth-oauthlib-0.4.6 grpcio-1.43.0 markdown-3.3.6 oauthlib-3.1.1 protobuf-3.19.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install opencv-python\n",
    "!pip install torchvision\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcffae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base import BaseDataSet, BaseDataLoader\n",
    "from utils import palette\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a0c20b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_label = 255\n",
    "ID_TO_TRAINID = {-1: ignore_label, 0: ignore_label, 1: ignore_label, 2: ignore_label,\n",
    "                    3: ignore_label, 4: ignore_label, 5: ignore_label, 6: ignore_label,\n",
    "                    7: 0, 8: 1, 9: ignore_label, 10: ignore_label, 11: 2, 12: 3, 13: 4,\n",
    "                    14: ignore_label, 15: ignore_label, 16: ignore_label, 17: 5,\n",
    "                    18: ignore_label, 19: 6, 20: 7, 21: 8, 22: 9, 23: 10, 24: 11, 25: 12, 26: 13, 27: 14,\n",
    "                    28: 15, 29: ignore_label, 30: ignore_label, 31: 16, 32: 17, 33: 18}\n",
    "\n",
    "class CityScapesDataset(BaseDataSet):\n",
    "    def __init__(self, mode='fine', **kwargs):\n",
    "        self.num_classes = 19\n",
    "        self.mode = mode\n",
    "        self.palette = palette.CityScpates_palette\n",
    "        self.id_to_trainId = ID_TO_TRAINID\n",
    "        super(CityScapesDataset, self).__init__(**kwargs)\n",
    "\n",
    "    def _set_files(self):\n",
    "        assert (self.mode == 'fine' and self.split in ['train', 'val']) or \\\n",
    "        (self.mode == 'coarse' and self.split in ['train', 'train_extra', 'val'])\n",
    "\n",
    "        SUFIX = '_gtFine_labelIds.png'\n",
    "        if self.mode == 'coarse':\n",
    "            img_dir_name = 'leftImg8bit_trainextra' if self.split == 'train_extra' else 'leftImg8bit_trainvaltest'\n",
    "            label_path = os.path.join(self.root, 'gtCoarse', 'gtCoarse', self.split)\n",
    "        else:\n",
    "            img_dir_name = 'leftImg8bit_trainvaltest'\n",
    "            label_path = os.path.join(self.root, 'gtFine_trainvaltest', 'gtFine', self.split)\n",
    "        image_path = os.path.join(self.root, img_dir_name, 'leftImg8bit', self.split)\n",
    "        assert os.listdir(image_path) == os.listdir(label_path)\n",
    "\n",
    "        image_paths, label_paths = [], []\n",
    "        for city in os.listdir(image_path):\n",
    "            image_paths.extend(sorted(glob(os.path.join(image_path, city, '*.png'))))\n",
    "            label_paths.extend(sorted(glob(os.path.join(label_path, city, f'*{SUFIX}'))))\n",
    "        self.files = list(zip(image_paths, label_paths))\n",
    "\n",
    "    def _load_data(self, index):\n",
    "        image_path, label_path = self.files[index]\n",
    "        image_id = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        image = np.asarray(Image.open(image_path).convert('RGB'), dtype=np.float32)\n",
    "        label = np.asarray(Image.open(label_path), dtype=np.int32)\n",
    "        for k, v in self.id_to_trainId.items():\n",
    "            label[label == k] = v\n",
    "        return image, label, image_id\n",
    "\n",
    "\n",
    "\n",
    "class CityScapes(BaseDataLoader):\n",
    "    def __init__(self, data_dir, batch_size, split, crop_size=None, base_size=None, scale=True, num_workers=1, mode='fine', val=False,\n",
    "                    shuffle=False, flip=False, rotate=False, blur= False, augment=False, val_split= None, return_id=False):\n",
    "\n",
    "        self.MEAN = [0.28689529, 0.32513294, 0.28389176]\n",
    "        self.STD = [0.17613647, 0.18099176, 0.17772235]\n",
    "\n",
    "        kwargs = {\n",
    "            'root': data_dir,\n",
    "            'split': split,\n",
    "            'mean': self.MEAN,\n",
    "            'std': self.STD,\n",
    "            'augment': augment,\n",
    "            'crop_size': crop_size,\n",
    "            'base_size': base_size,\n",
    "            'scale': scale,\n",
    "            'flip': flip,\n",
    "            'blur': blur,\n",
    "            'rotate': rotate,\n",
    "            'return_id': return_id,\n",
    "            'val': val\n",
    "        }\n",
    "\n",
    "        self.dataset = CityScapesDataset(mode=mode, **kwargs)\n",
    "        super(CityScapes, self).__init__(self.dataset, batch_size, shuffle, num_workers, val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d64c1878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "folders = glob('./data/a2d2-preview/camera_lidar_semantic/*/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b429385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "for folder in folders:\n",
    "    folders2 = glob(folder+'*/')\n",
    "    for folder2 in folders2:\n",
    "        if folder2.split('/')[-2] == 'camera':\n",
    "            folders3 = glob(folder2+'/*')\n",
    "            for folder3 in folders3:\n",
    "                images = glob(folder3+'/*.png')\n",
    "                for img in images:\n",
    "                    shutil.copy(img, './data/a2d2/camera_lidar_semantic/images/')\n",
    "                    \n",
    "        elif folder2.split('/')[-2] == 'label':\n",
    "            folders3 = glob(folder2+'/*')\n",
    "            for folder3 in folders3:\n",
    "                labels = glob(folder3+'/*.png')\n",
    "                for label in labels:\n",
    "                    shutil.copy(label, './data/a2d2/camera_lidar_semantic/labels/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4226732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
